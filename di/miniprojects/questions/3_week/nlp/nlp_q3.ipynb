{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# nlp_q3.ipynb Bigram Model\n",
    "\n",
    "Review Input:\n",
    "BigramModel \n",
    "{u'text': u\"Love it!!!!! Love it!!!!!! love it!!!!!!!   Who doesn't love Culver's!\"}\n",
    "BigramModel \n",
    "{u'text': u'Everything was great except for the burgers they are greasy and very charred compared to other stores.'}\n",
    "BigramModel \n",
    "{u'text': u'I really like both Chinese restaurants in town.  This one has outstanding crab rangoon.  Love the chicken with snow peas and mushrooms and General Tso Chicken.  Food is always ready in 10 minutes which is accurate.  Good place and they give you free pop.'}\n",
    "BigramModel \n",
    "{u'text': u'Above average takeout with friendly staff. The sauce on the pan fried noodle is tasty. Dumplings are quite good.'}\n",
    "BigramModel \n",
    "{u'text': u\"We order from Chang Jiang often and have never been disappointed.  The menu is huge, and can accomodate anyone's taste buds.  The service is quick, usually ready in 10 minutes.\"}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import simplejson as json\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3000 reviews\n"
     ]
    }
   ],
   "source": [
    "lst_reviews = []\n",
    "lst_stars = []\n",
    "lst_tst = []\n",
    "\n",
    "# build feature lists from random rows\n",
    "with open(\"/home/vagrant/miniprojects/questions/3_week/nlp/data/tiny_review.json\") as f:\n",
    "    for line in f:\n",
    "        tmp = json.loads(line)\n",
    "        lst_reviews.append(tmp['text'])\n",
    "        lst_stars.append(tmp['stars'])\n",
    "        \n",
    "# reviews come out tokenized- each review is 1 string, but not\n",
    "# vectorized\n",
    "y = lst_stars\n",
    "print len(lst_stars), \"reviews\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Define stopwords ###\n",
    "\n",
    "# import nltk\n",
    "# stops = nltk.corpus.stopwords.words('english')\n",
    "\n",
    "# nltk corpus may not be available on heroku:\n",
    "stops = [u'i', u'me', u'my', u'myself', u'we', u'our', u'ours', u'ourselves', u'you', u'your', u'yours', u'yourself', u'yourselves', u'he', u'him', u'his', u'himself', u'she', u'her', u'hers', u'herself', u'it', u'its', u'itself', u'they', u'them', u'their', u'theirs', u'themselves', u'what', u'which', u'who', u'whom', u'this', u'that', u'these', u'those', u'am', u'is', u'are', u'was', u'were', u'be', u'been', u'being', u'have', u'has', u'had', u'having', u'do', u'does', u'did', u'doing', u'a', u'an', u'the', u'and', u'but', u'if', u'or', u'because', u'as', u'until', u'while', u'of', u'at', u'by', u'for', u'with', u'about', u'against', u'between', u'into', u'through', u'during', u'before', u'after', u'above', u'below', u'to', u'from', u'up', u'down', u'in', u'out', u'on', u'off', u'over', u'under', u'again', u'further', u'then', u'once', u'here', u'there', u'when', u'where', u'why', u'how', u'all', u'any', u'both', u'each', u'few', u'more', u'most', u'other', u'some', u'such', u'no', u'nor', u'not', u'only', u'own', u'same', u'so', u'than', u'too', u'very', u's', u't', u'can', u'will', u'just', u'don', u'should', u'now']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<type 'numpy.ndarray'> <class 'scipy.sparse.csr.csr_matrix'>\n",
      "(3000, 100000)\n"
     ]
    }
   ],
   "source": [
    "## only need if the input is not tokenized\n",
    "# bigram, lengths 1 and 2 with hashing vectorizer\n",
    "import nltk.tokenize\n",
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "\n",
    "parameters = {'input':lst_reviews, 'decode_error':'ignore',\n",
    "              'ngram_range':(1,2), 'non_negative':True, 'n_features':100000,\n",
    "              'stop_words':stops}\n",
    "ng_counter = HashingVectorizer(**parameters)\n",
    "\n",
    "counts=ng_counter.fit_transform(lst_reviews)\n",
    "\n",
    "X = counts\n",
    "print counts.shape\n",
    "\n",
    "# __ reviews, ___ unique words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Cross Validate ###\n",
    "X_trn, X_tst, y_trn, y_tst = train_test_split(X, y, test_size=0.25)\n",
    "\n",
    "print X_train.shape, len(y_train)\n",
    "print X_test.shape, len(y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# truncate this massive sparse matrix by SVD\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "svd = TruncatedSVD(n_components=100)\n",
    "\n",
    "X_trn_tiny = svd.fit_transform(X_trn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<type 'numpy.ndarray'> (3000, 100)\n",
      "0.0829893138809\n"
     ]
    }
   ],
   "source": [
    "print type(X_trn_tiny), X_trn_tiny.shape\n",
    "print X_trn_tiny[0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# train the classifier\n",
    "from sklearn.linear_model import LinearRegression\n",
    "lnr = LinearRegression().fit(X_trn_tiny, lst_stars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/home/vagrant/miniprojects/questions/3_week/nlp/pickles/q2_model.pkl',\n",
       " '/home/vagrant/miniprojects/questions/3_week/nlp/pickles/q2_model.pkl_01.npy',\n",
       " '/home/vagrant/miniprojects/questions/3_week/nlp/pickles/q2_model.pkl_02.npy']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# save the model\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "joblib.dump(lnr,'/home/vagrant/miniprojects/questions/3_week/nlp/pickles/q2_model.pkl')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# \"import\" a new testing set\n",
    "X_tst = X_trn[1500:2500] \n",
    "random.shuffle(X_tst)\n",
    "print X_tst.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 100000)\n"
     ]
    }
   ],
   "source": [
    "X_tst = lst_tst\n",
    "X_tst = ng_counter.fit_transform(X_tst).toarray()\n",
    "\n",
    "print X_tst.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 100)\n"
     ]
    }
   ],
   "source": [
    "# if this was raw strings, it would need to be hash vectorized\n",
    "# since it's already in this form, we can svd it, then run predict\n",
    "X_tst_tiny = svd.transform(X_tst)\n",
    "\n",
    "print X_tst_tiny.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "p = lnr.predict(X_tst_tiny)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 2.87064916  3.25740874  3.21098448  3.58275315  4.15341595  2.17057596\n",
      "  3.43758947  2.46798879  3.59993311  2.04720853  4.85214216  3.69692738\n",
      "  2.41675093  3.52719658  2.79235823  2.84885614  3.86368597  3.49994699\n",
      "  3.79819504  3.77745403  2.87364152  4.31719149  3.07291298  3.5758968\n",
      "  4.96167515  2.79290435  1.89914632  3.542675    4.99239213  3.84442084\n",
      "  2.43657226  3.72134614  3.73407898  2.87970679  4.06141634  3.24574102\n",
      "  2.8887286   4.07996691  4.31824134  1.84470265  3.04631997  3.41363337\n",
      "  4.51585433  4.56391276  4.26518821  3.52655678  3.28357723  4.38392247\n",
      "  4.26349294  4.46233032  2.62094397  3.12754667  2.84641709  4.31719149\n",
      "  3.30855275  3.65357261  3.71242116  3.05625629  3.6277285   3.05013919\n",
      "  4.02434239  3.7433118   3.24103483  3.5758968   4.56101521  4.86162379\n",
      "  3.54489123  4.25206442  3.35128282  2.84954176  2.88977188  4.13585638\n",
      "  4.02451749  3.89241406  2.05482908  3.37966117  2.77152674  2.8414837\n",
      "  3.22012299  2.91927728  3.80895915  2.71910234  4.02371311  2.55009435\n",
      "  2.84836553  2.88164709  3.0287738   4.59972043  5.7793047   3.0979169\n",
      "  2.87970679  2.88459053  3.95957709  3.96726164  4.56391276  3.20304062\n",
      "  3.35128282  4.66502984  2.68803116  3.11769799  4.5087001   3.4235595\n",
      "  2.97149971  3.96734516  3.30227125  4.04859897  3.22183733  2.77556164\n",
      "  2.85683692  4.83890982  3.2367527   3.00045969  2.73222449  3.01913721\n",
      "  2.93190914  5.27647763  4.04298174  5.18868853  4.83890982  4.12997535\n",
      "  4.03072248  3.89809562  3.63246106  3.52823069  3.87786838  2.74784134\n",
      "  1.71767794  3.64971516  3.66296683  5.31638028  2.39479886  4.43765299\n",
      "  3.26512565  4.53449571  2.59751218  3.5689158   5.12655455  4.96144622\n",
      "  3.18915921  3.69692738  3.40904539  4.4166354   3.70069867  2.77398099\n",
      "  2.77829558  3.69246991  3.60086515  3.64693849  3.82983847  4.34068672\n",
      "  3.61726936  3.44743561  2.18986233  3.5506284   2.81311716  3.50405802\n",
      "  4.51585433  4.13417123  5.54853869  3.42444318  5.90666306  4.53730013\n",
      "  3.56957881  3.86985211  4.54550066  4.12784969  2.75629887  3.80895915\n",
      "  3.04320421  3.59047154  3.58692749  3.29727911  3.23930919  4.08989936\n",
      "  0.66003422  3.64971516  3.85437864  3.79226435  5.74026781  3.42693297\n",
      "  4.29971305  2.79235823  3.09522319  4.31692137  4.25206442  4.29562184\n",
      "  5.11044152  2.65354096  4.41570696  4.16582591  3.80690098  4.04610673\n",
      "  4.34644308  5.28761388  5.38825192  3.61552071  2.29345756  5.04119854\n",
      "  3.75466116  5.21684105  3.09265147  3.73407898  4.0130437   3.72662722\n",
      "  3.31754221  4.77474988  4.22351891  5.14697602  3.93618633  3.46069726\n",
      "  4.87708821  2.98251413  2.64386651  3.24097712  2.88164709  4.65865267\n",
      "  4.63220777  3.4624922   5.2228233   3.22644308  2.98998064  4.13417123\n",
      "  2.67022711  3.09905909  3.89809562  2.51787349  4.33022848  2.83430184\n",
      "  4.06141634  2.88514578  3.42490506  3.71431295  4.11544464  3.48574669\n",
      "  4.10563092  2.89680284  3.22470818  4.60838321  2.04720853  2.77152674\n",
      "  3.73193045  4.10563092  4.50103512  2.93923319  3.74699437  4.41077071\n",
      "  2.88973921  4.51216266  4.42392919  5.07400503  4.32301927  4.12784969\n",
      "  4.71582158  3.67687819  4.34644308  2.63553829  3.90672545  3.74699437\n",
      "  2.54407942  4.51648204  4.20628736  4.13796219  4.54550066  3.13430374\n",
      "  3.96487517  4.25314225  3.74173504  3.50405802  5.74026781  3.80617581\n",
      "  3.66296683  4.12561211  2.82496526  3.75466116  3.67714297  3.54489123\n",
      "  4.02527573  2.18986233  2.88301572  3.97257029  3.52655678  3.75037448\n",
      "  3.13258319  2.94514475  4.04083185  2.89680284  2.89137486  2.69142135\n",
      "  2.9797348   3.10201207  3.63475794  3.47628445  3.40904539  4.21262884\n",
      "  2.11484362  2.84025979  2.21389384  3.89241406  4.07871704  2.74505941\n",
      "  4.43515392  3.62469037  3.34049826  4.52882073  4.41502232  4.12561211\n",
      "  2.97649284  3.64971516  3.90709286  4.51648204  3.54489123  3.4122099\n",
      "  3.87383854  4.53449571  2.01655336  3.81401246  3.83240987  3.48024752\n",
      "  2.72126427  4.29788268  4.31760903  3.12033129  3.35773097  3.35423579\n",
      "  3.95775466  4.06974451  4.07223914  2.65488968  1.73931983  4.07222897\n",
      "  4.05675651  4.0351886   2.49197026  3.35514785  3.2070198   3.24393212\n",
      "  2.93571227  2.92904853  4.02434239  2.66949138  3.64971516  3.77779823\n",
      "  2.71662136  4.71105013  3.3553334   3.35128282  4.96750372  3.63921252\n",
      "  3.93847401  4.29971305  4.78880052  3.24574894  4.66502984  4.05142753\n",
      "  3.96734516  2.6330105   4.19510294  4.63081077  3.08139086  4.29971305\n",
      "  2.27673473  2.41535146  2.11484362  4.03944496  4.55887898  4.41570696\n",
      "  3.59993311  3.61224815  3.63666164  3.77995307  4.34375022  3.64971516\n",
      "  4.467036    3.19355488  3.44220688  2.57117822  2.75555958  4.13283157\n",
      "  3.14961662  3.68402669  3.42693297  4.45106308  2.57175647  4.52457125\n",
      "  3.52719658  3.52655678  4.51648204  3.47419962  4.18767265  3.87786838\n",
      "  2.04720853  2.0290091   3.2384685   2.97149971  2.88514578  3.98625404\n",
      "  2.33273034  3.0244442   4.26660217  3.81294288  3.11769799  4.28713846\n",
      "  3.542675    3.24103483  3.81294288  4.03944496  4.51597467  3.82717275\n",
      "  5.5498381   2.81311716  4.10096828  3.68402669  3.04649057  3.05992399\n",
      "  2.19713679  2.19999759  4.15333686  3.79096502  3.48306792  3.8495911\n",
      "  3.93519304  2.70082571  3.61027101  3.38206273  2.99463577  4.74730823\n",
      "  3.74205136  4.07996691  4.12353773  3.68081601  2.88514578  3.2739871\n",
      "  4.23256077  4.90949607  2.94648682  3.10543909  3.30227125  4.19466843\n",
      "  2.89013038  5.12655455  4.00315593  2.79047968  4.43515392  2.40737697\n",
      "  3.54904236  4.00774524  5.2592531   3.30227125  2.8887286   3.23271952\n",
      "  3.91972949  2.59632159  3.81294288  3.96349658  4.91563724  2.02716138\n",
      "  3.08139086  4.80931556  4.05211857  3.27197593  2.51506252  2.69937795\n",
      "  3.21021075  4.04610673  4.76663455  3.09905909  5.26909867  3.13890727\n",
      "  3.75961297  3.95392611  4.90949607  2.75555958  3.7766075   2.91837753\n",
      "  2.81311716  2.56504374  2.41085075  3.67150248  4.75341387  4.02371311\n",
      "  3.25681929  2.90235145  4.83890982  2.97609372  3.69246991  4.61963514\n",
      "  5.15976496  3.14581912  3.8447065   2.75851192  4.46130485  1.92624764\n",
      "  3.34049826  2.70460304  3.35128282  3.90321538  3.90672545  4.31034922\n",
      "  2.49116106  4.58903727  3.5758968   5.2228233   4.62566614  2.69937795\n",
      "  4.5558315   3.79819504  3.7766075   4.45106308  4.62379067  5.84566871\n",
      "  5.46154678  3.14961662  2.69612781  4.41570696  4.41570696  3.39332477\n",
      "  5.32280647  2.93918498  3.39332477  3.43149289  3.51982209  2.57117822\n",
      "  3.48651372  4.97499942  3.74959793  2.88164709  4.46130485  4.92059149\n",
      "  3.29727911  4.1587154   4.13352709  4.7615393   3.84661273  4.70483546\n",
      "  4.88783826  3.51184029  3.74173504  3.30795155  4.04312507  2.43470248\n",
      "  2.67022711  5.90666306  2.65798581  4.14702278  3.73193045  4.0344772\n",
      "  4.20488613  3.78202229  3.22173726  2.87064916  4.23158763  4.12784969\n",
      "  3.09343751  1.9064498   2.92904853  3.7433118   4.36934661  4.06974451\n",
      "  5.8361227   3.29166452  5.08904243  2.63553829  2.77556164  5.12200896\n",
      "  4.238595    3.84797386  3.46110238  3.94900477  4.2872491   2.62094397\n",
      "  4.15505336  2.94648682  3.12033129  3.26545702  2.6182657   3.76561757\n",
      "  2.93923319  3.63844705  4.18169805  3.67939316  4.42048423  4.26372443\n",
      "  3.18835439  4.08089253  4.46655085  3.04125234  2.6500114   3.10360951\n",
      "  3.96989006  2.55841796  2.32343171  3.87383854  1.97206338  3.77351162\n",
      "  5.44263703  2.83569504  2.40619211  3.35128282  3.01913721  2.57175647\n",
      "  4.92755698  3.57087338  4.60083906  4.34602772  4.06141634  1.4234231\n",
      "  4.25996111  2.9740332   3.72662722  3.36549608  3.4009626   2.52975592\n",
      "  2.65555717  3.52719658  2.26871719  3.81340772  2.83981018  3.41033994\n",
      "  2.91423114  3.07646989  3.80578588  4.21018657  1.19292269  3.69257828\n",
      "  2.89013038  3.52655678  4.04312507  3.46069726  3.22183733  3.01301002\n",
      "  3.27197593  3.93618633  3.93487017  3.3667565   4.36334336  4.39509524\n",
      "  2.27952875  3.74568225  3.54489123  4.46512838  4.48780197  3.24773161\n",
      "  3.79096502  1.97243924  3.90658033  3.65613232  4.82006931  2.78661227\n",
      "  4.73718618  4.00921441  3.1800059   3.70069867  4.20901431  4.08543101\n",
      "  4.52882073  4.60401557  3.41366612  3.31307479  2.99103091  3.11678837\n",
      "  3.13282026  5.277419    3.17670911  3.65284881  3.24465645  1.99909179\n",
      "  4.13352709  3.6109145   4.19007265  4.25705278  3.72662722  3.29367951\n",
      "  3.56809683  3.24103483  4.06141634  3.69246991  2.77829558  4.51585433\n",
      "  4.6361859   2.04496869  4.52882073  3.93618633  3.74982691  3.85384676\n",
      "  2.09342639  4.50103512  3.66296683  4.80845778  5.07400503  5.12200896\n",
      "  4.38605963  4.99030719  3.14328521  2.18141525  4.08365248  3.23341442\n",
      "  4.21335365  3.48553606  3.9952253   3.40827824  3.34051765  3.60771007\n",
      "  2.918934    3.2881824   3.30672586  2.75555958  4.7439953   3.47809523\n",
      "  3.45409207  3.23178734  4.61405142  5.07400503  1.8288437   2.87970679\n",
      "  4.87708821  2.71885087  3.8302513   4.70540993  4.69381632  3.68426705\n",
      "  3.79819504  3.13634809  3.22012299  5.04726189  4.13632985  3.40406758\n",
      "  5.59942571  3.70777773  2.43470248  3.032794    3.23341442  2.66949138\n",
      "  3.73193045  4.12928831  3.42648859  4.57538856  3.2292124   2.93277035\n",
      "  3.45409207  4.05443086  3.02107772  2.18141525  2.88722732  4.54550066\n",
      "  4.92059149  2.86477165  3.19511518  3.25307887  3.77779823  3.47364476\n",
      "  4.40620483  4.13737971  5.12708945  4.92599905  2.79235823  4.17679522\n",
      "  2.78661227  3.29909409  2.62200097  2.4127096   3.43758947  3.72163361\n",
      "  1.8288437   3.56344033  3.34144705  3.54489123  3.79229916  3.5862213\n",
      "  2.88514578  3.85384676  2.98524473  2.40189187  3.60901041  4.22351891\n",
      "  3.30227125  3.22470818  3.27495065  4.15320351  2.85505168  2.8887286\n",
      "  3.26806659  5.00352499  2.57358592  4.75341387  2.04720853  3.25962529\n",
      "  4.42392919  4.18767265  3.63068563  2.40189187  3.49547981  3.99542595\n",
      "  3.77818964  4.39207917  4.27068535  3.48225213  2.63743062  4.18100791\n",
      "  3.28350688  3.24570536  4.52730223  3.97446907  3.77289232  3.62469037\n",
      "  2.49197026  2.79235823  4.21158453  4.43515392  3.84974556  4.06138039\n",
      "  3.50761285  3.13705412  3.67156497  3.76424477  4.30585564  2.27673473\n",
      "  4.39509524  2.79378988  3.72972223  3.59993311  4.92599905  3.52655678\n",
      "  2.88278636  2.94648682  3.81340772  2.68803116  3.67418653  3.13258319\n",
      "  2.85582766  3.09522319  2.79235823  4.31034922  2.9740332   2.33630549\n",
      "  0.98254166  3.9375414   2.918934    3.47364476  3.03534882  3.2384685\n",
      "  3.59507883  3.38206273  4.08256857  3.77479586  3.26354525  3.37484831\n",
      "  4.53836564  3.24103483  3.91695842  3.64210272  3.57563227  3.56344033\n",
      "  3.80690098  3.73401444  3.63135183  3.12033129  3.0359962   3.1800059\n",
      "  4.66396499  4.06205524  4.51597467  3.98785011  2.91457155  3.66216382\n",
      "  2.99771749  3.79226435  3.08103218  4.38901736  2.94648682  3.96142711\n",
      "  3.1800059   4.23158763  1.81860019  2.49842945  4.26169812  2.57358592\n",
      "  3.56957881  4.47289298  3.45073843  4.87158318  4.13283157  2.67152392\n",
      "  2.88164709  4.43765299  2.48048404  3.85363486  3.51797333  4.3171168\n",
      "  2.59632159  2.037346    4.28900463  3.35128282  4.13061264  2.99336015\n",
      "  4.78688856  4.14666765  3.98367172  3.90709286  3.44298692  3.01913721\n",
      "  2.86623066  2.56021315  3.75535217  3.09905909  2.77152674  5.12655455\n",
      "  3.73407898  3.25143852  4.467036    3.06430241  3.83240987  2.57502158\n",
      "  4.12928831  3.24354802  3.59423397  3.08658336  4.19683331  3.29727911\n",
      "  1.68723134  2.07076689  3.77479586  3.88884317  3.65613232  4.04029174\n",
      "  4.36334336  3.2070198   2.49842945  3.14200395  2.49116106  3.39091965\n",
      "  3.66216382  2.78661227  3.01890946  3.43758947  3.18973034  2.6330105\n",
      "  3.81294288  2.70239357  3.62207139  4.03706758  3.07010314  3.05334007\n",
      "  4.56740639  4.22287508  4.13283157  2.53075418  3.81014573  2.85361968\n",
      "  3.24097712  3.57261025  3.49267486  3.28357723  3.74635691  4.95586805\n",
      "  1.92964999  3.93519304  3.07291298  4.28900463  4.12561211  3.72134614\n",
      "  1.83300602  2.04720853  4.93918638  1.93465183  4.45307711  3.09343751\n",
      "  3.23930919  3.49710356  3.22644308  1.59821349  2.4647394   4.50468162\n",
      "  3.8191361   3.64971516  2.46767682  3.79819504  4.53323669  3.18915921\n",
      "  1.66677494  1.25175251  4.71294788  2.57502158  5.02271212  3.0287738\n",
      "  3.89166797  3.45573312  5.59942571  4.36334336  3.20217925  4.48780197\n",
      "  2.84954176  3.25927834  2.75505108  3.83566229  4.54550066  2.89137486\n",
      "  3.22644308  2.58928476  4.02338493  5.04119854]\n"
     ]
    }
   ],
   "source": [
    "print p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "lst_reviews = []\n",
    "lst_stars = []\n",
    "lst_tst = []\n",
    "\n",
    "i = 0  # counter\n",
    "\n",
    "#lst_sample_mask = random.sample(range(1,1012913),3000)\n",
    "lst_sample_mask = random.sample(range(1,4000),3000)\n",
    "\n",
    "# build feature lists from random rows\n",
    "with open(\"/home/vagrant/miniprojects/questions/3_week/nlp/data/tiny_review.json\") as f:\n",
    "    for line in f:\n",
    "        if i in lst_sample_mask:\n",
    "            tmp = json.loads(line)\n",
    "            lst_reviews.append(tmp['text'])\n",
    "            lst_stars.append(tmp['stars'])\n",
    "        else:\n",
    "            lst_tst.append(tmp['text'])\n",
    "        i += 1\n",
    "# reviews come out tokenized- each review is 1 string, but not\n",
    "# vectorized\n",
    "y = lst_stars\n",
    "print len(lst_stars), \"reviews\"\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
