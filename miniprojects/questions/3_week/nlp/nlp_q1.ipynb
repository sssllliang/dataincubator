{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# nlp_q1.ipynb BagOfWordsModel\n",
    "\n",
    "Review Input:\n",
    "BagOfWordsModel \n",
    "{u'text': u\"Love it!!!!! Love it!!!!!! love it!!!!!!!   Who doesn't love Culver's!\"}\n",
    "BagOfWordsModel \n",
    "{u'text': u'Everything was great except for the burgers they are greasy and very charred compared to other stores.'}\n",
    "BagOfWordsModel \n",
    "{u'text': u'I really like both Chinese restaurants in town.  This one has outstanding crab rangoon.  Love the chicken with snow peas and mushrooms and General Tso Chicken.  Food is always ready in 10 minutes which is accurate.  Good place and they give you free pop.'}\n",
    "BagOfWordsModel \n",
    "{u'text': u'Above average takeout with friendly staff. The sauce on the pan fried noodle is tasty. Dumplings are quite good.'}\n",
    "BagOfWordsModel \n",
    "{u'text': u\"We order from Chang Jiang often and have never been disappointed.  The menu is huge, and can accomodate anyone's taste buds.  The service is quick, usually ready in 10 minutes.\"}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import simplejson as json\n",
    "import random\n",
    "from sklearn.cross_validation import train_test_split\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "pd.options.display.max_rows = 999\n",
    "from sklearn.externals import joblib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Constants\n",
    "\n",
    "PATH_PKL = '/home/vagrant/miniprojects/questions/3_week/nlp/pickles/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1012913 reviews\n"
     ]
    }
   ],
   "source": [
    "\n",
    "lst_reviews = []\n",
    "lst_stars = []\n",
    "lst_len = []\n",
    "\n",
    "with open(\"/home/vagrant/miniprojects/questions/3_week/nlp/data/yelp_train_academic_dataset_review.json\") as f:\n",
    "    for line in f:\n",
    "        tmp = json.loads(line)\n",
    "        lst_reviews.append(tmp['text'])\n",
    "        lst_stars.append(tmp['stars'])\n",
    "        lst_len.append(len(tmp['text']))\n",
    "# reviews come out tokenized- each review is 1 string, but not\n",
    "# vectorized\n",
    "print len(lst_stars), \"reviews\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Define stopwords ###\n",
    "\n",
    "# import nltk\n",
    "# stops = nltk.corpus.stopwords.words('english')\n",
    "\n",
    "# nltk corpus may not be available on heroku:\n",
    "stops = [u'i', u'me', u'my', u'myself', u'we', u'our', u'ours', u'ourselves', u'you', u'your', u'yours', u'yourself', u'yourselves', u'he', u'him', u'his', u'himself', u'she', u'her', u'hers', u'herself', u'it', u'its', u'itself', u'they', u'them', u'their', u'theirs', u'themselves', u'what', u'which', u'who', u'whom', u'this', u'that', u'these', u'those', u'am', u'is', u'are', u'was', u'were', u'be', u'been', u'being', u'have', u'has', u'had', u'having', u'do', u'does', u'did', u'doing', u'a', u'an', u'the', u'and', u'but', u'if', u'or', u'because', u'as', u'until', u'while', u'of', u'at', u'by', u'for', u'with', u'about', u'against', u'between', u'into', u'through', u'during', u'before', u'after', u'above', u'below', u'to', u'from', u'up', u'down', u'in', u'out', u'on', u'off', u'over', u'under', u'again', u'further', u'then', u'once', u'here', u'there', u'when', u'where', u'why', u'how', u'all', u'any', u'both', u'each', u'few', u'more', u'most', u'other', u'some', u'such', u'no', u'nor', u'not', u'only', u'own', u'same', u'so', u'than', u'too', u'very', u's', u't', u'can', u'will', u'just', u'don', u'should', u'now']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1012913, 18164)\n"
     ]
    }
   ],
   "source": [
    "# bag of words \n",
    "import nltk\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "cv = CountVectorizer(stops, min_df=100, max_df=1.0, max_features=100000)\n",
    "\n",
    "counts = cv.fit_transform(lst_reviews)\n",
    "X = counts\n",
    "y = lst_stars\n",
    "print counts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Delete stop words to reduce file size\n",
    "delattr(cv, 'stop_words_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/home/vagrant/miniprojects/questions/3_week/nlp/pickles/q1_cv.pkl']"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(bag_of_words_vectorizer, PATH_PKL + 'q1_cv.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/home/vagrant/miniprojects/questions/3_week/nlp/pickles/q1_cv.pkl']"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Save massive vectorized array & vectorizer\n",
    "joblib.dump(counts, PATH_PKL + 'q1_arr_counts.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(759684, 18164) 759684\n",
      "(253229, 18164) 253229\n"
     ]
    }
   ],
   "source": [
    "## Cross Validate ###\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25)\n",
    "\n",
    "print X_train.shape, len(y_train)\n",
    "print X_test.shape, len(y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# optimize a regresser (LinearRegression)\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "\n",
    "parameters = {'alpha':[.01, .1, .2, .5, 1.]}\n",
    "rgr = GridSearchCV(Ridge(), parameters)\n",
    "\n",
    "X = X_train[0:100000,:]\n",
    "y = y_train[0:100000]\n",
    "\n",
    "rgr.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None,\n",
       "       estimator=Ridge(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None,\n",
       "   normalize=False, solver='auto', tol=0.001),\n",
       "       fit_params={}, iid=True, loss_func=None, n_jobs=1,\n",
       "       param_grid={'alpha': [0.01, 0.1, 0.2, 0.5, 1.0]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, score_func=None, scoring=None,\n",
       "       verbose=0)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alpha': 1.0}\n",
      "Ridge(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None,\n",
      "   normalize=False, solver='auto', tol=0.001)\n",
      "0.282398408295\n",
      "Ridge(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None,\n",
      "   normalize=False, solver='auto', tol=0.001)\n"
     ]
    }
   ],
   "source": [
    "print rgr.best_params_\n",
    "print rgr.best_estimator_\n",
    "print rgr.best_score_\n",
    "print rgr.get"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ridge(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None,\n",
       "   normalize=False, solver='auto', tol=0.001)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the optimized regressor\n",
    "ridge = Ridge(alpha=1.0)\n",
    "\n",
    "ridge.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/home/vagrant/miniprojects/questions/3_week/nlp/pickles/q1_lrr.pkl',\n",
       " '/home/vagrant/miniprojects/questions/3_week/nlp/pickles/q1_lrr.pkl_01.npy']"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# save the regresser model\n",
    "joblib.dump(ridge,'/home/vagrant/miniprojects/questions/3_week/nlp/pickles/q1_lrr.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ridge = joblib.load('/home/vagrant/miniprojects/questions/3_week/nlp/pickles/q1_lrr.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 4.12257203  2.90971301  3.68648693 ...,  4.44168538  3.73465754\n",
      "  3.96391873]\n"
     ]
    }
   ],
   "source": [
    "p = ridge.predict(X_test) # define a transform method in clf to take raw strings\n",
    "print p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.50892793653387214"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ridge.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lst_q1 = [\n",
    "            \"Love it!!!!! Love it!!!!!! love it!!!!!!!   Who doesn't love Culver's!\",\n",
    "    'Everything was great except for the burgers they are greasy and very charred compared to other stores.',\n",
    "    'I really like both Chinese restaurants in town.  This one has outstanding crab rangoon.  Love the chicken with snow peas and mushrooms and General Tso Chicken.  Food is always ready in 10 minutes which is accurate.  Good place and they give you free pop.',\n",
    "    'Above average takeout with friendly staff. The sauce on the pan fried noodle is tasty. Dumplings are quite good.',\n",
    "    \"We order from Chang Jiang often and have never been disappointed.  The menu is huge, and can accomodate anyone's taste buds.  The service is quick, usually ready in 10 minutes.\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5]\n",
      "[4]\n",
      "[4]\n",
      "[3]\n",
      "[5]\n"
     ]
    }
   ],
   "source": [
    "## From Validation Input\n",
    "\n",
    "t1 = bag_of_words_vectorizer.transform([\"Love it!!!!! Love it!!!!!! love it!!!!!!!   Who doesn't love Culver's!\"])\n",
    "print clf.predict(t1)\n",
    "\n",
    "t1 = bag_of_words_vectorizer.transform(['Everything was great except for the burgers they are greasy and very charred compared to other stores.'])\n",
    "print clf.predict(t1)\n",
    "\n",
    "t1 = bag_of_words_vectorizer.transform(['I really like both Chinese restaurants in town.  This one has outstanding crab rangoon.  Love the chicken with snow peas and mushrooms and General Tso Chicken.  Food is always ready in 10 minutes which is accurate.  Good place and they give you free pop.'])\n",
    "print clf.predict(t1)\n",
    "\n",
    "t1 = bag_of_words_vectorizer.transform(['Above average takeout with friendly staff. The sauce on the pan fried noodle is tasty. Dumplings are quite good.'])\n",
    "print clf.predict(t1)\n",
    "\n",
    "t1 = bag_of_words_vectorizer.transform([\"We order from Chang Jiang often and have never been disappointed.  The menu is huge, and can accomodate anyone's taste buds.  The service is quick, usually ready in 10 minutes.\"])\n",
    "print clf.predict(t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "## bag of with HashingVectorizer ###\n",
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "\n",
    "bag_of_words_vectorizer = HashingVectorizer(n_features=int(1e5))\n",
    "\n",
    "counts = bag_of_words_vectorizer.fit_transform(lst_reviews)\n",
    "X_trn = counts\n",
    "print counts.shape\n",
    "\n",
    "# __ reviews, ___ unique words"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
